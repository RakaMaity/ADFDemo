{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "Test1TrialADF"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/dataflowAggr')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "DataFlowSourceDepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "TotalEmpBasedOnDeptwithRole",
							"rejectedDataLinkedService": {
								"referenceName": "LinkedServiceTest1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1Aggr1AndDeptRole"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          department as string,",
						"          role as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee aggregate(groupBy(department),",
						"     TotalEmployees = count(empid),",
						"     partitionBy('hash', 1)) ~> aggregate1",
						"aggregate1, department join(aggregate1@department == department@department,",
						"     joinType:'outer',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1Aggr1AndDeptRole",
						"join1Aggr1AndDeptRole sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmpOnDeptwithRole.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          department = aggregate1@department,",
						"          TotalEmployees,",
						"          role",
						"     ),",
						"     partitionBy('hash', 1)) ~> TotalEmpBasedOnDeptwithRole"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowAlterRowTransform')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "sourceEmployees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRowEmployee"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> sourceEmployees",
						"sourceEmployees alterRow(deleteIf(equals(department,\"Physics\")),",
						"     updateIf(equals(department,\"Law\"))) ~> alterRowEmployee",
						"alterRowEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowAssert')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "sourceEmployee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sinkOutput"
						}
					],
					"transformations": [
						{
							"name": "assertEmployeeRows"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "filterGoodRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> sourceEmployee",
						"sourceEmployee assert(expectTrue(!equalsIgnoreCase(location, \"Dallas\"), false, 'assertLocation'),",
						"     expectUnique(empid, false, 'assertEmpId')) ~> assertEmployeeRows",
						"assertEmployeeRows derive(isError = isError()) ~> derivedColumn1",
						"derivedColumn1 filter(isError()==false()) ~> filterGoodRows",
						"filterGoodRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department",
						"     )) ~> sinkOutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowBranch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "DataFlowSourceDepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "joinSink"
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "EmpCountSink"
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "SinkLookUp"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "joinempanddept"
						},
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          department as string,",
						"          role as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee aggregate(groupBy(gender),",
						"     TotalEmployees = count(gender)) ~> aggregate1",
						"employee, department join(employee@department == department@department,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinempanddept",
						"employee, department lookup(employee@department == department@department,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"joinempanddept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['joinempanddept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department = employee@department,",
						"          role",
						"     ),",
						"     partitionBy('hash', 1)) ~> joinSink",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['genderwithempcount.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          gender,",
						"          TotalEmployees",
						"     ),",
						"     partitionBy('hash', 1)) ~> EmpCountSink",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['lookup.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department = employee@department,",
						"          dept = department@department,",
						"          role",
						"     ),",
						"     partitionBy('hash', 1)) ~> SinkLookUp"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowCSVjoin')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "DataFlowSourceDepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "joinOutput",
							"rejectedDataLinkedService": {
								"referenceName": "LinkedServiceTest1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "employeeJOINdepartment"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          department as string,",
						"          role as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department join(employee@department == department@department,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> employeeJOINdepartment",
						"employeeJOINdepartment sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empjoindeptoutput.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          role",
						"     ),",
						"     partitionBy('hash', 1)) ~> joinOutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowCacheSink')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataSet_SQLServer",
								"type": "DatasetReference"
							},
							"name": "employees"
						},
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "Employee"
						}
					],
					"sinks": [
						{
							"name": "MaxCountofEmpId"
						},
						{
							"dataset": {
								"referenceName": "DataSet_SQLServer",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "selectcolumns"
						},
						{
							"name": "surrogateKey1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          MaxEmpId as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select max(empId) as MaxEmpId from dbo.employee',",
						"     format: 'query') ~> employees",
						"source(output(",
						"          empid as long,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"Employee select(mapColumn(",
						"          empName,",
						"          gender,",
						"          location,",
						"          department",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectcolumns",
						"selectcolumns keyGenerate(output(empId as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 derive(empId = empId+MaxCountofEmpId#outputs()[1].MaxEmpId) ~> derivedColumn1",
						"employees sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 0,",
						"     mapColumn(",
						"          MaxEmpId",
						"     )) ~> MaxCountofEmpId",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empId as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowCacheSinkOutputToActivity')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "WindowDataSet",
								"type": "DatasetReference"
							},
							"name": "employees"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string,",
						"          Salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employees",
						"employees aggregate(MaxSalary = max(toInteger(Salary))) ~> aggregate1",
						"aggregate1 sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowConditionalSplit')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "BiologyEmpSink"
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "PhysicsEmpSink"
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "LawEmpSink"
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "OtherEmpSink"
						}
					],
					"transformations": [
						{
							"name": "SplitBasedOnDept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees split(equalsIgnoreCase(department,\"biology\"),",
						"     equalsIgnoreCase(department,\"law\"),",
						"     equalsIgnoreCase(department,\"physics\"),",
						"     disjoint: false) ~> SplitBasedOnDept@(BiologyEmployees, LawEmployees, PhysicsEmployees, Others)",
						"SplitBasedOnDept@BiologyEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['BiologyEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> BiologyEmpSink",
						"SplitBasedOnDept@PhysicsEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['PhysicsEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> PhysicsEmpSink",
						"SplitBasedOnDept@LawEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['LawEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> LawEmpSink",
						"SplitBasedOnDept@Others sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['PsychologyEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> OtherEmpSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowDerivedColumn')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "EmpWithRegion"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee derive(gender = upper(gender),",
						"          region = iif(equalsIgnoreCase(location, \"Mexico\"),\"Central America\",\"North America\"),",
						"          experience = case(equalsIgnoreCase(empName,\"ABC\"),5\r",
						",equalsIgnoreCase(empName,\"WTR\"),10,equalsIgnoreCase(empName,\"TGF\"),15,equalsIgnoreCase(empName,\"ITE\"),20)) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeeWithRegion.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> EmpWithRegion"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowExists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "DataFlowSourceDepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "employeeExists"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          department as string,",
						"          role as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department exists(employee@department == iif(equals(department@department,'Law'),\"Law\",\"\"),",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['employeeExists.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> employeeExists"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowFilterTrans')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "FilteredEmployees",
							"rejectedDataLinkedService": {
								"referenceName": "LinkedServiceTest1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "filteremployeesbasedondept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     limit: 10,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee filter(notEquals(department,\"Biology\")) ~> filteremployeesbasedondept",
						"filteremployeesbasedondept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['FilteredEmployees.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department",
						"     ),",
						"     partitionBy('hash', 1)) ~> FilteredEmployees"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowJSONEmp')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmpJSONDataSet",
								"type": "DatasetReference"
							},
							"name": "EmployeeJSONData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "EmpJSONOutput",
								"type": "DatasetReference"
							},
							"name": "FlattenedJSONoutput",
							"description": "when flatten is used, arraydata type values are converted into multiple rows."
						},
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						},
						{
							"name": "stringifyJSON"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          age as short,",
						"          contact as (email as string, phone as string),",
						"          department as string,",
						"          email as string,",
						"          first_name as string,",
						"          gender as string,",
						"          id as boolean,",
						"          job_title as string,",
						"          last_name as string,",
						"          phone as string,",
						"          salary as short,",
						"          skills as string[],",
						"          years_of_experience as boolean",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'singleDocument') ~> EmployeeJSONData",
						"EmployeeJSONData foldDown(unroll(skills),",
						"     mapColumn(",
						"          id,",
						"          first_name,",
						"          last_name,",
						"          gender,",
						"          age,",
						"          contact,",
						"          skills,",
						"          department,",
						"          job_title,",
						"          salary,",
						"          years_of_experience",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"EmployeeJSONData stringify(contact = contact ? string,",
						"     format: 'json') ~> stringifyJSON",
						"stringifyJSON derive(contact = toString(contact)) ~> derivedColumn1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeesJSONOutput'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          first_name,",
						"          last_name,",
						"          age,",
						"          contact,",
						"          department,",
						"          gender,",
						"          job_title,",
						"          salary,",
						"          skills,",
						"          years_of_experience",
						"     ),",
						"     partitionBy('hash', 1)) ~> FlattenedJSONoutput",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empJSON.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          age,",
						"          contact,",
						"          department,",
						"          first_name,",
						"          gender,",
						"          id,",
						"          job_title,",
						"          last_name,",
						"          salary,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowLookup')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "DataFlowSourceDepartment",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "LookUpOutput",
							"rejectedDataLinkedService": {
								"referenceName": "LinkedServiceTest1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "lookupEMpAndDept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          department as string,",
						"          role as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department lookup(Employee@department == Department@department,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookupEMpAndDept",
						"lookupEMpAndDept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeeLookUp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department = Employee@department,",
						"          dept = Department@department,",
						"          role",
						"     ),",
						"     partitionBy('hash', 1)) ~> LookUpOutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowParameteriztn')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employeedata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sinkEMployeesParam"
						}
					],
					"transformations": [
						{
							"name": "filterEmployeeOndept"
						}
					],
					"scriptLines": [
						"parameters{",
						"     Dept as string",
						"}",
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeedata",
						"employeedata filter(department != $Dept) ~> filterEmployeeOndept",
						"filterEmployeeOndept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EMployeesParam.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sinkEMployeesParam"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowParse')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_SQL_Employee11",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "employeeSink"
						}
					],
					"transformations": [
						{
							"name": "parseSkills"
						},
						{
							"name": "parselocation"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empId as integer,",
						"          empName as string,",
						"          skills as string,",
						"          location as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> employee",
						"employee parse(skills = skills ? (skill1 as string,",
						"          skill2 as string,",
						"          skill3 as string),",
						"     format: 'delimited',",
						"     columnNamesAsHeader: false,",
						"     columnDelimiter: '|',",
						"     nullValue: '') ~> parseSkills",
						"parseSkills parse(location = location ? (city as string,",
						"          country as string),",
						"     format: 'json',",
						"     documentForm: 'singleDocument') ~> parselocation",
						"parselocation sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['employeeparsedoutput.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empId,",
						"          empName,",
						"          Skill1 = skills.skill1,",
						"          Skill2 = skills.skill2,",
						"          Skill3 = skills.skill3,",
						"          City = location.city,",
						"          Country = location.country",
						"     ),",
						"     partitionBy('hash', 1)) ~> employeeSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowPivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "SinkPivot"
						}
					],
					"transformations": [
						{
							"name": "pivotEmployee"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee pivot(groupBy(department),",
						"     pivotBy(gender),",
						"     {} = count(empid),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivotEmployee",
						"pivotEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SinkPivotEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> SinkPivot"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowRank')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "WindowDataSet",
								"type": "DatasetReference"
							},
							"name": "sourceEMployees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sinkEompoyeesWithRank"
						}
					],
					"transformations": [
						{
							"name": "rankofEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string,",
						"          Salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> sourceEMployees",
						"sourceEMployees rank(asc(Salary, true),",
						"     output(Rank as long),",
						"     dense: true) ~> rankofEmployees",
						"rankofEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeesWithRank.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department,",
						"          Salary,",
						"          Rank",
						"     ),",
						"     partitionBy('hash', 1)) ~> sinkEompoyeesWithRank"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowSelectTransform')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "EmployeePostSelectOperation"
						}
					],
					"transformations": [
						{
							"name": "selectEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee select(mapColumn(",
						"          EmployeeId = empid,",
						"          EmpName = empName,",
						"          Location = location,",
						"          Department = department,",
						"          Gender = gender",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectEmployees",
						"selectEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeePostSelectOperation.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmployeeId,",
						"          EmpName,",
						"          Location,",
						"          Department,",
						"          Gender",
						"     ),",
						"     partitionBy('hash', 1)) ~> EmployeePostSelectOperation"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowSortTransform')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sinkEmployees"
						}
					],
					"transformations": [
						{
							"name": "sortEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees sort(asc(empName, true)) ~> sortEmployees",
						"sortEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmployeesSorted.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department",
						"     ),",
						"     partitionBy('hash', 1)) ~> sinkEmployees"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowSurrogateKey')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DataFlowSourceEmployee",
								"type": "DatasetReference"
							},
							"name": "Employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedTextOutput",
								"type": "DatasetReference"
							},
							"name": "sinkSurrogateKey"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empName as string,",
						"          gender as string,",
						"          location as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"Employee keyGenerate(output(RollNo as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          RollNo,",
						"          empid,",
						"          empName,",
						"          gender,",
						"          location,",
						"          department",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['sinkSurrogateKey.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sinkSurrogateKey"
					]
				}
			},
			"dependsOn": []
		}
	]
}